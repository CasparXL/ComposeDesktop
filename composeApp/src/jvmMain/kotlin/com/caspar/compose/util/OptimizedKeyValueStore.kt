package com.caspar.compose.util

import kotlinx.coroutines.*
import kotlinx.coroutines.sync.Mutex
import kotlinx.coroutines.sync.withLock
import kotlinx.serialization.*
import kotlinx.serialization.json.*
import java.io.*
import java.nio.file.Files
import java.nio.file.StandardCopyOption
import java.util.zip.GZIPInputStream
import java.util.zip.GZIPOutputStream
import kotlin.coroutines.CoroutineContext
import kotlin.math.abs
import kotlin.time.Duration
import kotlin.time.Duration.Companion.seconds

/**
 * æœ¬åœ°æŒä¹…åŒ–é”®å€¼å¯¹å­˜å‚¨
 */
@OptIn(ExperimentalSerializationApi::class, DelicateCoroutinesApi::class)
class OptimizedKeyValueStore(
    baseDir: File,
    private val json: Json = Json {
        ignoreUnknownKeys = true
        prettyPrint = false
    },
    private val writeDelay: Duration = 3.seconds,
    private val enableCompression: Boolean = true,
    private val shardCount: Int = 16,
    private val coroutineContext: CoroutineContext = Dispatchers.IO + SupervisorJob()
) {
    private val logHelper = this.logger
    private val shards = List(shardCount) { shardIndex ->
        Shard(
            file = File(baseDir, "prefs_shard_${shardIndex}.json${if (enableCompression) ".gz" else ""}"),
            json = json,
            enableCompression = enableCompression,
            writeDelay = writeDelay,
            coroutineContext = coroutineContext + CoroutineName("Shard-$shardIndex")
        )
    }
    private val scope = CoroutineScope(coroutineContext + CoroutineName("StoreManager"))
    private var isClosed = false
    private val initJob: Deferred<Unit>

    init {
        baseDir.mkdirs()
        initJob = scope.async(Dispatchers.IO) {
            // å¹¶è¡ŒåŠ è½½æ‰€æœ‰åˆ†ç‰‡
            shards.map { shard -> async { shard.loadAsync() } }.awaitAll()

            // âœ… å®‰å…¨è·å–æ€»é¡¹æ•°ï¼ˆåœ¨åç¨‹å†…è°ƒç”¨ suspend å‡½æ•°ï¼‰
            val totalItems = shards.map { shard ->
                async { shard.getCacheSize() }
            }.awaitAll().sum()

            logHelper.info("âœ… å­˜å‚¨åˆå§‹åŒ–å®Œæˆ | åˆ†ç‰‡: $shardCount | æ€»é¡¹æ•°: $totalItems | è·¯å¾„: ${baseDir.absolutePath}")
        }
    }

    private fun getShard(key: String) = shards[abs(key.hashCode()) % shardCount]

    /** ä»å†…å­˜ç¼“å­˜è¯»å–ï¼ˆè‡ªåŠ¨ç­‰å¾…åˆå§‹åŒ–ï¼‰ */
    suspend fun <T> get(key: String, serializer: KSerializer<T>): T? {
        if (isClosed) return null
        initJob.await()
        return getShard(key).get(key, serializer)
    }

    /** å†™å…¥å†…å­˜ç¼“å­˜ + æ™ºèƒ½å»¶è¿ŸæŒä¹…åŒ– */
    suspend fun <T> put(key: String, value: T, serializer: KSerializer<T>): Boolean {
        if (isClosed) return false
        initJob.await()
        return getShard(key).put(key, value, serializer)
    }

    suspend fun delete(key: String): Boolean {
        if (isClosed) return false
        initJob.await()
        return getShard(key).delete(key)
    }

    suspend fun clear() {
        if (isClosed) return
        initJob.await()
        shards.forEach { it.clear() }
    }

    /** ç«‹å³æŒä¹…åŒ–æ‰€æœ‰åˆ†ç‰‡ï¼ˆå…³é”®æ“ä½œåè°ƒç”¨ï¼‰ */
    suspend fun flush(): Boolean {
        if (isClosed) return false
        return withContext(Dispatchers.IO) {
            shards.map { shard -> async { shard.flush() } }.awaitAll().all { it }
        }
    }

    /**
     * ä»…åˆ·æ–°åŒ…å«æŒ‡å®š Key çš„åˆ†ç‰‡ï¼ˆæ™ºèƒ½è·³è¿‡æ— å˜åŒ–åˆ†ç‰‡ï¼‰
     * é€‚ç”¨åœºæ™¯ï¼šä¿®æ”¹å•ä¸ª Key åéœ€ç«‹å³æŒä¹…åŒ–ï¼Œé¿å…å…¨é‡ flush
     */
    suspend fun flushForKey(key: String): Boolean {
        if (isClosed) return false
        initJob.await()
        return getShard(key).flush() // å†…éƒ¨å·²å«è„æ£€æŸ¥
    }

    /**
     * æ‰¹é‡åˆ·æ–°æŒ‡å®š Keys æ‰€åœ¨åˆ†ç‰‡ï¼ˆè‡ªåŠ¨å»é‡åˆ†ç‰‡ï¼‰
     */
    suspend fun flushForKeys(keys: Collection<String>): Boolean {
        if (isClosed || keys.isEmpty()) return true
        initJob.await()
        val shardsToFlush = keys.map { getShard(it) }.distinct()
        return withContext(Dispatchers.IO) {
            shardsToFlush.map { async { it.flush() } }.awaitAll().all { it }
        }
    }

    /** å®‰å…¨å…³é—­ï¼ˆåº”ç”¨é€€å‡ºå‰åŠ¡å¿…è°ƒç”¨ï¼‰ */
    suspend fun close() {
        if (isClosed) return
        isClosed = true
        try {
            flush()
        } finally {
            shards.forEach { it.close() }
            scope.coroutineContext[Job]?.cancel()
        }
    }
}

// =============== å†…éƒ¨ï¼šåˆ†ç‰‡å®ç°ï¼ˆé”ä¸åç¨‹å®‰å…¨è®¾è®¡ï¼‰ ===============
private class Shard(
    private val file: File,
    private val json: Json,
    private val enableCompression: Boolean,
    private val writeDelay: Duration,
    private val coroutineContext: CoroutineContext
) {
    private val logHelper = this.logger
    // ===== è„æ ‡è®°ï¼ˆå…³é”®ä¼˜åŒ–ï¼‰=====
    private var isDirty = false // æ ‡è®°ç¼“å­˜æ˜¯å¦éœ€æŒä¹…åŒ–
    private val cache = mutableMapOf<String, JsonElement>()
    private val mutex = Mutex()
    private val scope = CoroutineScope(coroutineContext)
    private var pendingWriteJob: Job? = null
    private var isClosed = false

    /** å¼‚æ­¥åŠ è½½åˆ†ç‰‡æ•°æ® */
    suspend fun loadAsync() = withContext(Dispatchers.IO) {
        if (!file.exists()) {
            mutex.withLock { isDirty = false }
            return@withContext
        }
        try {
            val content = if (enableCompression) {
                GZIPInputStream(file.inputStream()).use { it.reader().readText() }
            } else {
                file.readText()
            }
            if (content.isNotBlank()) {
                mutex.withLock {
                    cache.clear()
                    cache.putAll(json.decodeFromString(content))
                    isDirty = false // âœ… åŠ è½½å®Œæˆ = ä¸ç£ç›˜ä¸€è‡´
                    logHelper.info("ğŸ“¦ åˆ†ç‰‡åŠ è½½: ${file.name} | é¡¹æ•°: ${cache.size}")
                }
            }
        } catch (e: Exception) {
            logHelper.error("âš ï¸ åˆ†ç‰‡åŠ è½½å¤±è´¥ [${file.name}]: ${e.message} | æ–‡ä»¶å·²æ¸…ç†")
            file.delete()
            mutex.withLock { isDirty = false } // å¤±è´¥åè§†ä¸ºå¹²å‡€ï¼ˆç©ºç¼“å­˜ï¼‰
        }
    }

    /** å®‰å…¨è·å–ç¼“å­˜å¤§å°ï¼ˆéœ€åœ¨åç¨‹ä¸­è°ƒç”¨ï¼‰ */
    suspend fun getCacheSize(): Int = mutex.withLock { cache.size }

    /** éé˜»å¡è°ƒè¯•ç”¨ï¼ˆå…è®¸è½»å¾®ä¸ä¸€è‡´ï¼Œç»ä¸é˜»å¡çº¿ç¨‹ï¼‰ */
    val unsafeCacheSize: Int
        get() = cache.size // ä»…ç”¨äºæ—¥å¿—/ç›‘æ§ï¼Œæ ‡æ³¨"unsafe"

    suspend fun <T> get(key: String, serializer: KSerializer<T>): T? =
        mutex.withLock { cache[key]?.let { json.decodeFromJsonElement(serializer, it) } }

    suspend fun <T> put(key: String, value: T, serializer: KSerializer<T>): Boolean =
        mutex.withLock {
            val oldValue = cache[key]
            val newValue = json.encodeToJsonElement(serializer, value)
            // ä»…å½“å€¼çœŸæ­£å˜åŒ–æ—¶æ ‡è®°è„ä½ï¼ˆé¿å…æ— æ„ä¹‰å†™å…¥ï¼‰
            if (oldValue != newValue) {
                cache[key] = newValue
                isDirty = true
                scheduleWrite()
                true
            } else {
                false // å€¼æœªå˜ï¼Œè·³è¿‡
            }
        }

    suspend fun delete(key: String): Boolean =
        mutex.withLock {
            if (cache.remove(key) != null) {
                isDirty = true
                scheduleWrite()
                true
            } else false
        }

    suspend fun clear() = mutex.withLock {
        if (cache.isNotEmpty()) {
            cache.clear()
            isDirty = true
            scheduleWrite()
        }
    }

    suspend fun flush(): Boolean = mutex.withLock {
        if (isClosed || !isDirty) {
            if (!isDirty) logHelper.debug("â­ï¸ è·³è¿‡å†™å…¥ [${file.name}]ï¼šç¼“å­˜æœªå˜åŒ–")
            return@withLock true // æ— å˜åŒ–è§†ä¸ºæˆåŠŸ
        }
        pendingWriteJob?.cancelAndJoin()
        pendingWriteJob = null
        val success = writeSnapshotLocked(cache.toMap())
        if (success) isDirty = false
        success
    }

    // ===== è°ƒåº¦å†™å…¥ï¼šå‰ç½®è„æ£€æŸ¥ =====
    private fun scheduleWrite() {
        if (isClosed || !isDirty) return // âœ… æ— å˜åŒ–ä¸è°ƒåº¦
        pendingWriteJob?.cancel()
        pendingWriteJob = scope.launch {
            try {
                delay(writeDelay)
                if (isClosed) return@launch
                mutex.withLock {
                    if (isClosed || !isDirty) return@launch // å»¶è¿ŸæœŸé—´å¯èƒ½å·²è¢« flush
                    val success = writeSnapshotLocked(cache.toMap())
                    if (success) isDirty = false
                }
            } catch (e: CancellationException) {
                throw e
            } catch (e: Exception) {
                logHelper.error("âŒ åˆ†ç‰‡å†™å…¥å¼‚å¸¸ [${file.name}]: ${e.message}")
            }
        }
    }


    fun close() {
        isClosed = true
        pendingWriteJob?.cancel()
    }

    // âœ… é”å†…ä¸“ç”¨å†™å…¥ï¼ˆç”± mutex ä¿æŠ¤è°ƒç”¨ï¼‰
    private suspend fun writeSnapshotLocked(snapshot: Map<String, JsonElement>): Boolean =
        withContext(Dispatchers.IO) {
            if (isClosed) return@withContext false
            try {
                val tempFile = File("${file.absolutePath}.tmp")
                val content = json.encodeToString(snapshot)

                if (enableCompression) {
                    GZIPOutputStream(tempFile.outputStream()).use {
                        it.write(content.toByteArray(Charsets.UTF_8))
                    }
                } else {
                    tempFile.writeText(content, Charsets.UTF_8)
                }

                Files.move(tempFile.toPath(), file.toPath(), StandardCopyOption.REPLACE_EXISTING)
                val sizeKB = file.length() / 1024
                logHelper.info("åˆ†ç‰‡æŒä¹…åŒ–: ${file.name} | é¡¹æ•°: ${snapshot.size} | å¤§å°: ${if (sizeKB > 0) "${sizeKB}KB" else "<1KB"}")
                true
            } catch (e: Exception) {
                logHelper.error("ç£ç›˜å†™å…¥å¤±è´¥ [${file.name}]: ${e.message}")
                false
            }
        }
}